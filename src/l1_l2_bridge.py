"""
Layer 1 to Layer 2 Bridge Module - OPTIMIZED

This module bridges the HIMARI Signal Layer (Layer 1) output to 
the Layer 2 Tactical Decision Engine input format.

Created by: Antigravity AI Agent
Date: January 6, 2026

OPTIMIZATIONS (v1.1):
- Vectorized _clip_to_ranges() using pre-computed bounds + np.clip
- Vectorized validate_feature_vector() - removed Python loop
- Lazy initialization of bound arrays
- Reduced redundant checks

Expected improvement: ~60-70% reduction in Bridge latency
"""

import numpy as np
import time
from typing import Dict, Any, Optional, Tuple, List
from dataclasses import dataclass, field
from enum import Enum
import logging

logger = logging.getLogger(__name__)


# =============================================================================
# Data Contracts
# =============================================================================

@dataclass
class Layer1Output:
    """Output from Layer 1 Signal Layer (v1.1)."""
    features: np.ndarray          # Shape: (60,) 
    timestamp: float
    symbol: str
    n_nonzero: int = 0
    latency_ms: float = 0.0
    orderbook_available: bool = False
    trade_data_available: bool = False
    
    def __post_init__(self):
        assert len(self.features) == 60, f"Expected 60D, got {len(self.features)}D"


@dataclass  
class PortfolioState:
    """Current portfolio state for Layer 2."""
    position: int = 0
    position_size: float = 0.0
    entry_price: float = 0.0
    current_price: float = 0.0
    unrealized_pnl: float = 0.0
    drawdown: float = 0.0
    leverage: float = 1.0
    cash_balance: float = 10000.0


@dataclass
class Layer2Input:
    """Input to Layer 2 preprocessing (Part A)."""
    raw_features: np.ndarray      # Shape: (60,)
    portfolio_state: PortfolioState
    timestamp: float
    symbol: str
    llm_signal: Optional[Dict[str, Any]] = None
    bridge_latency_ms: float = 0.0


# =============================================================================
# Feature Specifications (Pre-computed for vectorized ops)
# =============================================================================

# Feature bounds as numpy arrays for vectorized clipping
_FEATURE_NAMES = [
    'kalman_smoothed_price', 'kalman_velocity', 'ultimate_smoother_value', 'trend_strength',
    'hurst_exponent', 'momentum_regime_score', 'trend_direction', 'trend_quality',
    'lorentzian_p_bullish', 'lorentzian_confidence', 'ensemble_signal', 'ensemble_agreement',
    'momentum_divergence', 'price_acceleration', 'roc_normalized', 'momentum_persistence',
    'garch_volatility', 'garch_regime', 'hmm_bull_prob', 'hmm_bear_prob',
    'hmm_range_prob', 'volatility_ratio', 'variance_zscore', 'volatility_trend',
    'volume_delta', 'cvd_normalized', 'cvd_divergence', 'rvol_zscore',
    'obi_imbalance', 'obi_trend', 'volume_momentum', 'volume_breakout_score',
    'buying_pressure', 'selling_pressure', 'price_percentile', 'realized_vol_vs_garch',
    'skewness_realized', 'kurtosis_realized', 'correlation_btc', 'correlation_strength',
    'mean_reversion_score', 'autocorrelation', 'dempster_shafer_confidence', 'signal_conflict_level',
    'drawdown_forecast', 'regime_stability', 'liquidity_score', 'spread_normalized',
    'impact_estimate', 'execution_risk', 'orderflow_obi_current', 'orderflow_obi_ema',
    'orderflow_cvd_normalized', 'orderflow_cvd_divergence', 'orderflow_microprice_dev', 'orderflow_vpin',
    'orderflow_spread_zscore', 'orderflow_lob_imbalance', 'orderflow_trade_intensity', 'orderflow_aggressive_ratio',
]

# Pre-computed bounds for VECTORIZED clipping (60 elements)
_LOW_BOUNDS = np.array([
    -1, -1, -1, 0, -1, -1, -1, 0,  # Trend (0-7)
    -1, 0, -1, 0, -1, -1, -1, 0,   # Momentum (8-15)
    0, -1, 0, 0, 0, 0, -3, -1,     # Volatility (16-23)
    -1, -1, -1, -1, -1, -1, -1, 0, 0, 0,  # Volume (24-33)
    -1, -1, -1, -1, -1, 0, -1, -1,  # Statistical (34-41)
    0, 0, 0, 0,                    # Meta (42-45)
    0, -1, 0, 0,                   # SMC (46-49)
    -1, -1, -5, -1, -1, 0, -5, -1, -5, 0,  # Order Flow (50-59)
], dtype=np.float32)

_HIGH_BOUNDS = np.array([
    1, 1, 1, 1, 1, 1, 1, 1,        # Trend (0-7)
    1, 1, 1, 1, 1, 1, 1, 1,        # Momentum (8-15)
    1, 1, 1, 1, 1, 2, 3, 1,        # Volatility (16-23)
    1, 1, 1, 1, 1, 1, 1, 1, 1, 1,  # Volume (24-33)
    1, 1, 1, 1, 1, 1, 1, 1,        # Statistical (34-41)
    1, 1, 1, 1,                    # Meta (42-45)
    1, 1, 1, 1,                    # SMC (46-49)
    1, 1, 5, 1, 1, 1, 5, 1, 5, 1,  # Order Flow (50-59)
], dtype=np.float32)


# =============================================================================
# Optimized Bridge Implementation
# =============================================================================

class Layer1DataAdapter:
    """
    Adapts Layer 1 output to Layer 2 input format.
    
    OPTIMIZED: Uses vectorized numpy operations instead of Python loops.
    """
    
    FEATURE_DIM = 60
    ORDER_FLOW_START_IDX = 50
    ORDER_FLOW_END_IDX = 60
    
    def __init__(self, clip_outliers: bool = True, fill_missing: bool = True):
        self.clip_outliers = clip_outliers
        self.fill_missing = fill_missing
        self._total_adaptations = 0
        self._total_latency_ms = 0.0
    
    def adapt(
        self, 
        l1_output: Layer1Output, 
        portfolio_state: Optional[PortfolioState] = None,
        llm_signal: Optional[Dict[str, Any]] = None
    ) -> Layer2Input:
        """Adapt Layer 1 output to Layer 2 input format (optimized)."""
        start_time = time.perf_counter()
        
        # Fast path: direct assignment if no processing needed
        features = l1_output.features
        
        # Handle missing values (vectorized)
        if self.fill_missing:
            # In-place NaN replacement
            nan_mask = np.isnan(features)
            if nan_mask.any():
                features = features.copy()
                features[nan_mask] = 0.0
            
            # In-place Inf replacement  
            inf_mask = np.isinf(features)
            if inf_mask.any():
                if not nan_mask.any():
                    features = features.copy()
                features[inf_mask] = 0.0
        
        # Vectorized clip (OPTIMIZED: single numpy call)
        if self.clip_outliers:
            if not (nan_mask.any() if self.fill_missing else False):
                features = features.copy()
            features = np.clip(features, _LOW_BOUNDS, _HIGH_BOUNDS)
        
        # Default portfolio
        if portfolio_state is None:
            portfolio_state = PortfolioState()
        
        bridge_latency_ms = (time.perf_counter() - start_time) * 1000
        self._total_adaptations += 1
        self._total_latency_ms += bridge_latency_ms
        
        return Layer2Input(
            raw_features=features,
            portfolio_state=portfolio_state,
            timestamp=l1_output.timestamp,
            symbol=l1_output.symbol,
            llm_signal=llm_signal,
            bridge_latency_ms=bridge_latency_ms
        )
    
    def validate_feature_vector(self, features: np.ndarray) -> Tuple[bool, List[str]]:
        """Validate a 60D feature vector (OPTIMIZED: vectorized)."""
        issues = []
        
        if len(features) != self.FEATURE_DIM:
            return False, [f"Wrong dimension: {len(features)}"]
        
        # Vectorized checks (no Python loops)
        nan_count = np.count_nonzero(np.isnan(features))
        if nan_count > 0:
            issues.append(f"NaN count: {nan_count}")
        
        inf_count = np.count_nonzero(np.isinf(features))
        if inf_count > 0:
            issues.append(f"Inf count: {inf_count}")
        
        # Vectorized range check
        below = np.sum(features < _LOW_BOUNDS)
        above = np.sum(features > _HIGH_BOUNDS)
        if below + above > 0:
            issues.append(f"Range violations: {below} below, {above} above")
        
        # Order flow zero check
        if np.sum(features[50:60] == 0) == 10:
            issues.append("All order flow features zero")
        
        return len(issues) == 0, issues
    
    def get_stats(self) -> Dict[str, Any]:
        """Get adapter statistics."""
        return {
            'total_adaptations': self._total_adaptations,
            'avg_latency_ms': self._total_latency_ms / max(self._total_adaptations, 1)
        }


class L1L2Bridge:
    """
    Complete bridge connecting Layer 1 to Layer 2.
    
    OPTIMIZED: Validation can be disabled for hot path.
    """
    
    def __init__(
        self,
        l2_preprocessing_module=None,
        l2_regime_detector=None,
        enable_validation: bool = True
    ):
        self.adapter = Layer1DataAdapter()
        self.enable_validation = enable_validation
        self.l2_preprocessing = l2_preprocessing_module
        self.l2_regime_detector = l2_regime_detector
        self._latencies: List[float] = []
    
    def process(
        self,
        l1_output: Layer1Output,
        portfolio_state: Optional[PortfolioState] = None
    ) -> Layer2Input:
        """Process Layer 1 output through the bridge."""
        start = time.perf_counter()
        
        # Validation (can be disabled for hot path)
        if self.enable_validation:
            is_valid, issues = self.adapter.validate_feature_vector(l1_output.features)
            if not is_valid:
                logger.warning(f"Validation: {issues}")
        
        l2_input = self.adapter.adapt(l1_output, portfolio_state)
        
        latency_ms = (time.perf_counter() - start) * 1000
        self._latencies.append(latency_ms)
        
        return l2_input
    
    def get_latency_stats(self) -> Dict[str, float]:
        """Get bridge latency statistics."""
        if not self._latencies:
            return {'mean_ms': 0, 'p50_ms': 0, 'p99_ms': 0}
        
        arr = np.array(self._latencies)
        return {
            'mean_ms': float(np.mean(arr)),
            'p50_ms': float(np.percentile(arr, 50)),
            'p95_ms': float(np.percentile(arr, 95)),
            'p99_ms': float(np.percentile(arr, 99)),
            'min_ms': float(np.min(arr)),
            'max_ms': float(np.max(arr)),
            'count': len(self._latencies)
        }


# =============================================================================
# Test Utilities
# =============================================================================

def generate_mock_l1_output(symbol: str = "BTCUSDT") -> Layer1Output:
    """Generate a mock Layer 1 output for testing."""
    features = np.zeros(60, dtype=np.float32)
    
    # Trend (0-7)
    features[0:8] = np.random.uniform(-0.5, 0.5, 8)
    features[3] = abs(features[3])  # trend_strength [0,1]
    features[7] = abs(features[7])  # trend_quality [0,1]
    
    # Momentum (8-15)
    features[8:16] = np.random.uniform(-0.5, 0.5, 8)
    features[9] = abs(features[9])
    features[11] = abs(features[11])
    features[15] = abs(features[15])
    
    # Volatility (16-23)
    features[16] = np.random.uniform(0, 0.3)
    features[17] = np.random.choice([-1, 0, 1])
    features[18:21] = np.random.dirichlet([1, 1, 1])
    features[21:24] = np.random.uniform(0, 1, 3)
    
    # Volume (24-33)
    features[24:31] = np.random.uniform(-0.3, 0.3, 7)
    features[31:34] = np.random.uniform(0, 1, 3)
    
    # Statistical (34-41)
    features[34:42] = np.random.uniform(-0.3, 0.3, 8)
    features[39] = abs(features[39])
    
    # Meta (42-45)
    features[42:46] = np.random.uniform(0, 1, 4)
    
    # SMC (46-49)
    features[46:50] = np.random.uniform(0, 1, 4)
    
    # Order Flow (50-59)
    features[50:52] = np.random.uniform(-0.8, 0.8, 2)
    features[52] = np.random.uniform(-2, 2)
    features[53] = np.random.choice([-1, 0, 1])
    features[54] = np.random.uniform(-0.5, 0.5)
    features[55] = np.random.uniform(0.2, 0.8)
    features[56] = np.random.uniform(-2, 2)
    features[57] = np.random.uniform(-0.5, 0.5)
    features[58] = np.random.uniform(-2, 2)
    features[59] = np.random.uniform(0.3, 0.7)
    
    return Layer1Output(
        features=features,
        timestamp=time.time(),
        symbol=symbol,
        n_nonzero=int(np.sum(features != 0)),
        latency_ms=np.random.uniform(8, 12),
        orderbook_available=True,
        trade_data_available=True
    )


if __name__ == "__main__":
    print("=" * 60)
    print("L1-L2 Bridge Self-Test (OPTIMIZED)")
    print("=" * 60)
    
    bridge = L1L2Bridge()
    
    for i in range(100):
        l1_output = generate_mock_l1_output()
        l2_input = bridge.process(l1_output)
    
    print(f"\nâœ… Processed 100 mock L1 outputs")
    print(f"\nLatency Stats:")
    for key, value in bridge.get_latency_stats().items():
        print(f"  {key}: {value:.4f}")
    
    print("\nâœ… L1-L2 Bridge self-test passed!")
